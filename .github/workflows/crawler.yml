name: Get Hot News

on:
  schedule:
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # âš ï¸ è¯•ç”¨ç‰ˆè¯´æ˜ / Trial Mode
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    #
    # ğŸ”„ è¿è¡Œæœºåˆ¶ / How it works:
    #    - æ¯ä¸ªå‘¨æœŸä¸º 7 å¤©ï¼Œå±Šæ—¶è‡ªåŠ¨åœæ­¢
    #    - è¿è¡Œ "Check In" ä¼šé‡ç½®å‘¨æœŸï¼ˆé‡æ–°å¼€å§‹ 7 å¤©å€’è®¡æ—¶ï¼Œè€Œéç´¯åŠ ï¼‰
    #    - Each cycle is 7 days, then auto-stops
    #    - "Check In" resets the cycle (restarts 7-day countdown, not cumulative)
    #
    # ğŸ’¡ è®¾è®¡åˆè¡· / Why this design:
    #    å¦‚æœ 7 å¤©éƒ½å¿˜äº†ç­¾åˆ°ï¼Œæˆ–è®¸è¿™äº›èµ„è®¯å¯¹ä½ æ¥è¯´å¹¶éåˆšéœ€
    #    é€‚æ—¶çš„æš‚åœï¼Œèƒ½å¸®ä½ ä»ä¿¡æ¯æµä¸­æŠ½ç¦»ï¼Œç»™å¤§è„‘ç•™å‡ºå–˜æ¯çš„ç©ºé—´
    #    If you forget for 7 days, maybe you don't really need it
    #    A timely pause helps you detach from the stream and gives your mind space
    #
    # ğŸ™ çæƒœèµ„æº / Respect shared resources:
    #    GitHub Actions æ˜¯å¹³å°æä¾›çš„å…¬å…±èµ„æºï¼Œæ¯æ¬¡è¿è¡Œéƒ½ä¼šæ¶ˆè€—ç®—åŠ›
    #    ç­¾åˆ°æœºåˆ¶ç¡®ä¿èµ„æºåˆ†é…ç»™çœŸæ­£éœ€è¦çš„ç”¨æˆ·ï¼Œæ„Ÿè°¢ä½ çš„ç†è§£ä¸é…åˆ
    #    GitHub Actions is a shared public resource provided by the platform
    #    Check-in ensures resources go to those who truly need it â€” thank you
    #
    # ğŸš€ é•¿æœŸä½¿ç”¨è¯·éƒ¨ç½² Docker ç‰ˆæœ¬ / For long-term use, deploy Docker version
    #
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    #
    # ğŸ“ è¿è¡Œæ—¶é—´è¯´æ˜ï¼šæ¯å¤©åŒ—äº¬æ—¶é—´æ—©ä¸Š8ç‚¹è¿è¡Œ
    # ğŸ“ Schedule: Daily 8:00 AM Beijing Time
    #
    # GitHub Actions ä½¿ç”¨ UTC æ—¶é—´ï¿½ï¿½ï¿½åŒ—äº¬æ—¶é—´ 8:00 = UTC 0:00
    # GitHub Actions uses UTC, Beijing 8:00 AM = UTC 0:00
    #
    # ç¤ºä¾‹ / Examples:
    #   "0 0 * * *"       â†’ æ¯å¤©åŒ—äº¬æ—¶é—´æ—©ä¸Š8ç‚¹ / Daily 8:00 AM Beijing
    #   "30 1 * * *"      â†’ æ¯å¤©åŒ—äº¬æ—¶é—´æ—©ä¸Š9:30 / Daily 9:30 AM Beijing
    #
    - cron: "0 0 * * *"

  workflow_dispatch:

concurrency:
  group: crawler-${{ github.ref_name }}
  cancel-in-progress: true

permissions:
  contents: read
  actions: write
  pull-requests: write

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          clean: true

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # è¯•ç”¨æœŸé™åˆ¶å·²ç§»é™¤ - å®šæ—¶ä»»åŠ¡å°†æ°¸ä¹…è¿è¡Œ
      # Trial period limit removed - Scheduled tasks will run permanently
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

      # --------------------------------------------------------------------------------
      # ğŸš¦ TRAFFIC CONTROL / æµé‡æ§åˆ¶
      # --------------------------------------------------------------------------------
      # EN: Generates a random delay between 1 and 300 seconds (5 minutes).
      #     Critical for load balancing.
      #
      # CN: ç”Ÿæˆ 1 åˆ° 300 ç§’ï¼ˆ5åˆ†é’Ÿï¼‰ä¹‹é—´çš„éšæœºå»¶è¿Ÿã€‚
      #     è¿™å¯¹è´Ÿè½½å‡è¡¡è‡³å…³é‡è¦ã€‚
      # - name: Random Delay (Traffic Control)
      #   if: success()
      #   run: |
      #     echo "ğŸ² Traffic Control: Generating random delay..."
      #     DELAY=$(( ( RANDOM % 300 )  + 1 ))
      #     echo "â¸ï¸  Sleeping for ${DELAY} seconds to spread the load..."
      #     sleep ${DELAY}s
      #     echo "â–¶ï¸  Delay finished. Starting crawler..."

      - name: Set up Python
        if: success()
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        if: success()
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Verify required files
        if: success()
        run: |
          if [ ! -f config/config.yaml ]; then
            echo "Error: Config missing"
            exit 1
          fi

      - name: Run crawler
        if: success()
        env:
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          DINGTALK_WEBHOOK_URL: ${{ secrets.DINGTALK_WEBHOOK_URL }}
          WEWORK_WEBHOOK_URL: ${{ secrets.WEWORK_WEBHOOK_URL }}
          WEWORK_MSG_TYPE: ${{ secrets.WEWORK_MSG_TYPE }}
          EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          EMAIL_TO: ${{ secrets.EMAIL_TO }}
          EMAIL_SMTP_SERVER: ${{ secrets.EMAIL_SMTP_SERVER }}
          EMAIL_SMTP_PORT: ${{ secrets.EMAIL_SMTP_PORT }}
          NTFY_TOPIC: ${{ secrets.NTFY_TOPIC }}
          NTFY_SERVER_URL: ${{ secrets.NTFY_SERVER_URL }}
          NTFY_TOKEN: ${{ secrets.NTFY_TOKEN }}
          BARK_URL: ${{ secrets.BARK_URL }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          # é€šç”¨Webhooké…ç½®
          GENERIC_WEBHOOK_URL: ${{ secrets.GENERIC_WEBHOOK_URL }}
          GENERIC_WEBHOOK_TEMPLATE: ${{ secrets.GENERIC_WEBHOOK_TEMPLATE }}
          # AI é…ç½®ï¼ˆai_analysis å’Œ ai_translation å…±äº«æ¨¡å‹é…ç½®ï¼‰
          AI_ANALYSIS_ENABLED: ${{ secrets.AI_ANALYSIS_ENABLED }}
          AI_API_KEY: ${{ secrets.AI_API_KEY }}
          AI_MODEL: ${{ secrets.AI_MODEL }}
          AI_API_BASE: ${{ secrets.AI_API_BASE }}
          # è¿œç¨‹å­˜å‚¨é…ç½®
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_ENDPOINT_URL: ${{ secrets.S3_ENDPOINT_URL }}
          S3_REGION: ${{ secrets.S3_REGION }}
          # GitHub åŒæ­¥é…ç½®
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
          GITHUB_ACTIONS: true
        run: python -m trendradar

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # GitHub åŒæ­¥æ­¥éª¤ - ä½¿ç”¨ Pythonï¼ˆåŒæ­¥ news å’Œ rss æ•°æ®ï¼‰
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      - name: Sync data to GitHub
        if: success()
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import sys
          import base64
          import json
          import urllib.request

          GH_TOKEN = os.environ.get('GH_TOKEN', '')
          REPO = '18815292408/TrendRadar'
          BRANCH = 'main'

          if not GH_TOKEN:
              print('GH_TOKEN æœªé…ç½®ï¼Œè·³è¿‡åŒæ­¥')
              sys.exit(0)

          print('æ­£åœ¨åŒæ­¥æ•°æ®åˆ° GitHub...')

          # è®¾ç½®è¯·æ±‚å¤´
          headers = {
              'Authorization': f'Bearer {GH_TOKEN}',
              'Accept': 'application/vnd.github.v3+json',
              'Content-Type': 'application/json'
          }

          def make_request(url, method='GET', data=None):
              req = urllib.request.Request(url, method=method, headers=headers)
              if data:
                  req.data = json.dumps(data).encode('utf-8')
              try:
                  with urllib.request.urlopen(req) as response:
                      return json.loads(response.read().decode('utf-8'))
              except Exception as e:
                  return {'error': str(e)}

          # è·å–å½“å‰åˆ†æ”¯ SHA
          ref_url = f'https://api.github.com/repos/{REPO}/git/ref/heads/{BRANCH}'
          ref_data = make_request(ref_url)
          if 'error' in ref_data:
              print(f'è·å–åˆ†æ”¯ä¿¡æ¯å¤±è´¥: {ref_data["error"]}')
              sys.exit(1)

          print(f'å½“å‰åˆ†æ”¯ SHA: {ref_data["object"]["sha"]}')

          # åŒæ­¥å‡½æ•°ï¼šåŒæ­¥æŒ‡å®šç›®å½•çš„æ•°æ®
          def sync_directory(dir_name, commit_prefix):
              dir_path = dir_name
              if not os.path.exists(dir_path):
                  print(f'ç›®å½• {dir_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡')
                  return 0

              db_files = [f for f in os.listdir(dir_path) if f.endswith('.db')]
              if not db_files:
                  print(f'ç›®å½• {dir_path} æ²¡æœ‰æ•°æ®åº“æ–‡ä»¶')
                  return 0

              print(f'ç›®å½• {dir_path}: å‘ç° {len(db_files)} ä¸ªæ•°æ®åº“æ–‡ä»¶')

              synced_count = 0
              for db_file in sorted(db_files):
                  filepath = os.path.join(dir_path, db_file)
                  print(f'  åŒæ­¥æ–‡ä»¶: {db_file}')

                  # è¯»å–æ–‡ä»¶å†…å®¹å¹¶ base64 ç¼–ç 
                  with open(filepath, 'rb') as f:
                      content = base64.b64encode(f.read()).decode('utf-8')

                  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                  content_url = f'https://api.github.com/repos/{REPO}/contents/{dir_path}/{db_file}'
                  existing = make_request(content_url)

                  # å‡†å¤‡è¯·æ±‚æ•°æ®
                  data = {
                      'message': f'{commit_prefix} - {db_file.replace(".db", "")}',
                      'content': content
                  }

                  if 'sha' in existing:
                      data['sha'] = existing['sha']
                      print(f'    æ›´æ–°ç°æœ‰æ–‡ä»¶ (SHA: {existing["sha"][:8]}...)')
                  else:
                      print(f'    åˆ›å»ºæ–°æ–‡ä»¶')

                  # ä¸Šä¼ æ–‡ä»¶
                  result = make_request(content_url, method='PUT', data=data)

                  if 'content' in result:
                      print(f'    âœ“ {db_file} åŒæ­¥æˆåŠŸ')
                      synced_count += 1
                  else:
                      print(f'    âœ— {db_file} åŒæ­¥å¤±è´¥: {result.get("message", result)}')

              return synced_count

          # åŒæ­¥æ–°é—»æ•°æ®
          news_count = sync_directory('output/news', 'åŒæ­¥çƒ­ç‚¹æ•°æ®')

          # åŒæ­¥ RSS æ•°æ®
          rss_count = sync_directory('output/rss', 'åŒæ­¥RSSè®¢é˜…')

          print('')
          print(f'åŒæ­¥å®Œæˆï¼æ–°é—»: {news_count} ä¸ªæ–‡ä»¶, RSS: {rss_count} ä¸ªæ–‡ä»¶')
          PYTHON_SCRIPT
